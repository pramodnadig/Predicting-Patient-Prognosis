{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMNJoluRYPZx00QkpwwfMQp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Importing"],"metadata":{"id":"rJ0iE-anKbfg"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Twkr1KugKQAp","executionInfo":{"status":"ok","timestamp":1676919113878,"user_tz":-330,"elapsed":1658,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}}},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import os"]},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86C7wLjCX3-j","executionInfo":{"status":"ok","timestamp":1676922576916,"user_tz":-330,"elapsed":4468,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}},"outputId":"0ba5b826-3c01-4ea2-dc39-943fcb7113c6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.1\n"]}]},{"cell_type":"markdown","source":["Dataset"],"metadata":{"id":"pXsim9KgW6vs"}},{"cell_type":"code","source":["df = pd.read_csv('/content/dataset.csv')\n","\n","print('Negative : {}'.format(len(df[df['hospital_death']==0])))\n","print('Positive : {}'.format(len(df[df['hospital_death']==1])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7lBF0L6W6ZD","executionInfo":{"status":"ok","timestamp":1676922398077,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}},"outputId":"826f2e6c-d90b-40e8-d8bf-4b0624e462df"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Negative : 8635\n","Positive : 570\n"]}]},{"cell_type":"code","source":["def clean_data(dataframe, \n","               solve_missing : str ='drop', \n","               solve_missing_cat : str = 'drop',\n","               drop_list : list = [], \n","               category_list : list = []): \n","    df = dataframe.drop_duplicates()\n","    df = df.drop(drop_list, axis=1)\n","    if solve_missing == 'drop' or solve_missing_cat == 'drop':\n","        df = df.dropna()#\n","        object_dtype = list(df.select_dtypes(include='object').columns)\n","        for col in df.columns:\n","            if col in category_list or col in object_dtype:\n","                df[col] = df[col].astype('category')\n","    else:\n","        object_dtype = list(df.select_dtypes(include='object').columns)\n","        for col in df.columns:\n","            if col in category_list or col in object_dtype:\n","                df[col] = df[col].astype('category')\n","                if solve_missing_cat == 'mode':#\n","                    df[col] = df[col].fillna(df[col].mode()[0], inplace=False)\n","            else:\n","                if solve_missing == 'mean':#\n","                    df[col] = df[col].fillna(df[col].mean(), inplace=False)\n","                else:#\n","                    df[col] = df[col].fillna(df[col].median(), inplace=False)\n","    return df\n","\n","def split_xy(dataframe, label : str):\n","    return dataframe.drop(labels=label, axis=1), dataframe[label]\n","\n","def encode(df):\n","    category_dtype = list(df.select_dtypes(include='category').columns)\n","    cat = pd.get_dummies(df, columns = category_dtype, drop_first = True)\n","    for col in cat.columns:\n","        if cat[col].dtype == np.uint8:\n","            cat[col] = cat[col].astype('category')\n","    return cat\n","\n","def scale(features : tuple):\n","    trainFeatures, valFeatures, testFeatures = features\n","    scaler = StandardScaler()\n","    category_dtype = list(trainFeatures.select_dtypes(include='category').columns)\n","    continuous_dtype = list(filter(lambda c: c not in category_dtype, trainFeatures.columns))\n","\n","    scaler.fit(trainFeatures[continuous_dtype])\n","    cont_xtrain = scaler.transform(trainFeatures[continuous_dtype])#\n","    cont_xval = scaler.transform(valFeatures[continuous_dtype])\n","    cont_xtest = scaler.transform(testFeatures[continuous_dtype])\n","    \n","    cat_xtrain = trainFeatures[category_dtype]\n","    cat_xval = valFeatures[category_dtype]\n","    cat_xtest = testFeatures[category_dtype]\n","    print(cat_xtrain.shape, cat_xval.shape, cat_xtrain.shape)\n","    xtrain = np.concatenate((cont_xtrain, cat_xtrain), axis=1)\n","    xval = np.concatenate((cont_xval, cat_xval), axis=1)\n","    xtest = np.concatenate((cont_xtest, cat_xtest), axis=1)\n","    return scaler, xtrain, xval, xtest"],"metadata":{"id":"KB9Pga8ZXXMt","executionInfo":{"status":"ok","timestamp":1676922442516,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["category_list = ['elective_surgery', 'ethnicity', 'icu_admit_source', 'icu_stay_type', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem', \n","                 'aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure', 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis', 'hospital_death']\n","drop_list = ['encounter_id', 'patient_id', 'hospital_id', 'Unnamed: 83']\n","clean_df = clean_data(df, 'drop', 'drop', drop_list, category_list)\n","print('Negative : {}'.format(len(clean_df[clean_df['hospital_death']==0])))\n","print('Positive : {}'.format(len(clean_df[clean_df['hospital_death']==1])))\n","# clean_df.info()\n","features, labels = split_xy(clean_df, 'hospital_death')\n","print(features.shape)\n","print(labels.shape)\n","####\n","encoded_features = encode(features)#one hot encoding\n","print('Encoded Features Shape : {}'.format(encoded_features.shape))\n","X_train, X_test, ytrain, ytest = train_test_split(encoded_features, labels, test_size = 0.2, stratify = labels)\n","X_test, X_val, ytest, yval = train_test_split(X_test, ytest, test_size = 0.5, stratify = ytest)\n","scaler, xtrain, xval, xtest = scale((X_train, X_val, X_test))\n","print(scaler.mean_)\n","print(scaler.var_)\n","print(xtrain.shape, ytrain.shape)\n","print(xval.shape, yval.shape)\n","print(xtest.shape, ytest.shape)\n","xtrain = np.array(xtrain, dtype='float32')\n","xval = np.array(xval, dtype='float32')\n","xtest = np.array(xtest, dtype='float32')\n","ytrain = np.array(ytrain, dtype='float32')\n","yval = np.array(yval, dtype='float32')\n","ytest = np.array(ytest, dtype='float32')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mo2m5saMXik1","executionInfo":{"status":"ok","timestamp":1676922472307,"user_tz":-330,"elapsed":1163,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}},"outputId":"6c805a2b-3659-4f56-d81c-2a3e75f04ed2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Negative : 4322\n","Positive : 281\n","(4603, 80)\n","(4603,)\n","Encoded Features Shape : (4603, 109)\n","(3682, 45) (461, 45) (3682, 45)\n","[6.21072787e+01 3.00508095e+01 1.69672102e+02 1.04745519e+02\n"," 5.63270830e-01 8.64883922e+01 1.78632808e+02 5.58511901e+02\n"," 1.71917436e-01 3.04182510e-02 3.57332971e+00 5.54345464e+00\n"," 0.00000000e+00 4.31884845e+00 1.00127648e+02 1.43400326e-01\n"," 9.83932645e+01 3.33256382e+01 3.64336882e+01 2.87343835e-01\n"," 8.90285171e+01 5.24913091e+01 8.90274307e+01 5.25024443e+01\n"," 1.05896524e+02 6.83742531e+01 1.13730038e+02 6.93552417e+01\n"," 1.14087724e+02 6.90809343e+01 3.42675177e+01 1.25263444e+01\n"," 9.92653449e+01 8.96632265e+01 1.57385932e+02 9.71450299e+01\n"," 1.57367463e+02 9.71499919e+01 3.73686193e+01 3.62747218e+01\n"," 7.78742531e+01 6.39022271e+01 7.79302010e+01 6.39546442e+01\n"," 9.47365562e+01 8.28489951e+01 9.92180880e+01 8.52096687e+01\n"," 9.93242803e+01 8.51567083e+01 2.57243346e+01 1.75717002e+01\n"," 9.80765888e+01 9.42281369e+01 1.40445139e+02 1.17364747e+02\n"," 1.40372895e+02 1.17326996e+02 1.72528789e+02 1.14369636e+02\n"," 4.19989136e+00 3.90521456e+00 8.47908745e-02 5.18305269e-02]\n","[2.80390175e+02 7.56372914e+01 1.12826519e+02 2.47033284e+02\n"," 4.82811546e+00 6.82767820e+02 7.09432905e+03 2.08547270e+05\n"," 1.42361831e-01 2.94929810e-02 8.14421776e-01 1.50069181e+00\n"," 0.00000000e+00 1.73809666e+00 1.00257523e+03 1.22836672e-01\n"," 1.67424404e+03 2.38369516e+02 7.41552937e-01 2.04777355e-01\n"," 2.91302011e+02 1.18236888e+02 2.92013099e+02 1.18342335e+02\n"," 5.31993367e+02 2.83719793e+02 4.59714193e+02 2.14387111e+02\n"," 4.54801376e+02 2.08225389e+02 1.55508282e+02 2.53199198e+01\n"," 1.43936937e+00 9.62939709e+01 8.07956163e+02 3.99806234e+02\n"," 8.09983656e+02 4.00008401e+02 4.39836087e-01 5.58617678e-01\n"," 2.89495595e+02 2.16713417e+02 2.90986166e+02 2.17780398e+02\n"," 5.52109305e+02 4.39021195e+02 4.60141194e+02 3.75697484e+02\n"," 4.57769367e+02 3.75338017e+02 7.55956544e+01 3.91411111e+01\n"," 4.72036990e+00 4.19881491e+01 9.46760841e+02 7.70295802e+02\n"," 9.46830803e+02 7.68496007e+02 7.75978747e+03 1.30208852e+03\n"," 4.09967397e-01 3.25029843e-01 4.17230551e-02 2.71717171e-02]\n","(3682, 109) (3682,)\n","(461, 109) (461,)\n","(460, 109) (460,)\n"]}]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"_C2xCEplXw9g"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torchmetrics import Accuracy, MeanSquaredError, Precision, Recall\n","\n","class Model(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(Model, self).__init__()\n","        self.layer1 = nn.Linear(input_dim, 1024)\n","        self.gnorm1 = nn.GroupNorm(32, 1024)\n","        \n","        self.layer2 = nn.Linear(1024, 512)\n","        self.gnorm2 = nn.GroupNorm(16, 512)\n","        \n","        self.layer3 = nn.Linear(512, 128)\n","        self.gnorm3 = nn.GroupNorm(4, 128)\n","        self.layer4 = nn.Linear(128, output_dim)\n","        \n","    def forward(self, x):\n","        x = F.relu(self.gnorm1(self.layer1(x)))\n","        x = F.relu(self.gnorm2(self.layer2(x)))\n","        x = F.relu(self.gnorm3(self.layer3(x)))\n","        x = torch.sigmoid(self.layer4(x))\n","        return x\n","\n","def L2(params):\n","    l2_lambda = 0.001\n","    l2_reg = torch.tensor(0.)\n","    for param in params:\n","        l2_reg += torch.sum(torch.pow(param, 2))\n","    return l2_lambda * l2_reg\n"],"metadata":{"id":"QMRwbSKUXpPG","executionInfo":{"status":"ok","timestamp":1676922585649,"user_tz":-330,"elapsed":645,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, x, y, device):\n","        self._x = x\n","        self._y = y\n","        self._device = device\n","\n","    def __len__(self):\n","        return len(self._x)\n","\n","    def __getitem__(self, idx):\n","        X, Y = self._x[idx], self._y[idx].ravel()\n","        return torch.as_tensor(X, dtype=torch.float32, device=self._device), torch.as_tensor(Y, dtype=torch.float32, device=self._device)\n","    \n","def train_loop(dataloader, valloader, model, loss_fn, optimizer, max_iter, metrics : dict, device):\n","    model.train()\n","    history = dict()\n","    history['Loss'] = []\n","    history['val_Loss'] = []\n","    for m in metrics:\n","        history[m['name']] = []\n","        history['val_{}'.format(m['name'])] = []\n","    size = len(dataloader.dataset)\n","    for itr in range(max_iter):\n","        real_time = dict()\n","        real_time['Loss'] = []\n","        for m in metrics:\n","            real_time[m['name']] = []\n","        for batch, (X, y) in enumerate(dataloader):\n","            \n","            X.to(device)\n","            y.to(device)\n","            pred = model(X)\n","            loss = loss_fn(pred, y)\n","            loss += L2(model.parameters())\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","           \n","            real_time['Loss'].append(loss.item())\n","            for m in metrics:\n","                if m['type'] == 'float':\n","                    real_time[m['name']].append(m['fn'](pred, y).item())\n","                else:\n","                    real_time[m['name']].append(m['fn'](pred, y.type(torch.uint8)).item())\n","        history['Loss'].append(np.mean(real_time['Loss']))\n","        for m in metrics:\n","            history[m['name']].append(np.mean(real_time[m['name']]))\n","            print(f\"{m['name']}: {np.mean(real_time[m['name']]):>8f}\", end='\\t')\n","        print('')\n","        epoch_loss = np.mean(real_time['Loss'])\n","        print(f\"Loss: {epoch_loss:>7f} [{itr:>5d}/{max_iter:>5d}]\")\n","        print('Val', end = '\\t')\n","        tmp = dict()\n","        tmp['Loss'] = []\n","        for m in metrics:\n","            tmp[m['name']] = []\n","        model.eval()\n","        with torch.no_grad():\n","            for X, y in valloader:\n","                X.to(device)\n","                y.to(device)\n","                pred = model(X)\n","                test_loss = loss_fn(pred, y)\n","                tmp['Loss'].append(test_loss.item())\n","                for m in metrics:\n","                    if m['type'] == 'float':\n","                        tmp[m['name']].append(m['fn'](pred, y).item())\n","                    else:\n","                        tmp[m['name']].append(m['fn'](pred, y.type(torch.uint8)).item())\n","        for k, v in tmp.items():\n","            print(f\"{k}: {np.mean(v):>8f}\", end='\\t')\n","            history['val_{}'.format(k)].append(np.mean(v))\n","        print('###END')\n","        \n","    return history"],"metadata":{"id":"oYMQGD4LZDks","executionInfo":{"status":"ok","timestamp":1676922869225,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Training and Validation"],"metadata":{"id":"17O5dhA3ZQv4"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model     = Model(xtrain.shape[-1], 1)#\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n","\n","if torch.cuda.is_available():\n","    loss_fn   = nn.BCELoss().cuda()#binary cross entropy\n","    metrics = [\n","        {'name': 'Accuracy', 'fn' : Accuracy(task=\"binary\").cuda(), 'type' : 'int'},\n","        {'name': 'MeanSquaredError', 'fn': MeanSquaredError().cuda(), 'type' : 'float'},\n","        {'name': 'Precision', 'fn': Precision(task=\"binary\").cuda(), 'type': 'int'},\n","        {'name': 'Recall', 'fn': Recall(task=\"binary\").cuda(), 'type':'int'}\n","    ]\n","    \n","else:\n","    loss_fn = nn.BCELoss().cpu()\n","    metrics = [\n","        {'name': 'Accuracy', 'fn' : Accuracy(task=\"binary\").cpu(), 'type' : 'int'},\n","        \n","    ]\n","train_dataset = CustomDataset(xtrain, ytrain, device)\n","val_dataset = CustomDataset(xval, yval, device)\n","test_dataset = CustomDataset(xtest, ytest, device)\n","train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"],"metadata":{"id":"wHIQA2VdZnu_","executionInfo":{"status":"ok","timestamp":1676923018127,"user_tz":-330,"elapsed":500,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","history = train_loop(train_loader, val_loader, model, loss_fn, optimizer, epochs,  metrics,device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDD9ZtSBZeHU","executionInfo":{"status":"ok","timestamp":1676923027500,"user_tz":-330,"elapsed":7878,"user":{"displayName":"Pramod Nadig","userId":"10731645578864687149"}},"outputId":"77f86553-87f5-4fe4-b056-8ddb08a69a81"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.763462\t\n","Loss: 2.830772 [    0/    5]\n","Val\tLoss: 0.580351\tAccuracy: 0.852495\t###END\n","Accuracy: 0.842761\t\n","Loss: 2.797851 [    1/    5]\n","Val\tLoss: 0.548298\tAccuracy: 0.891540\t###END\n","Accuracy: 0.893936\t\n","Loss: 2.765639 [    2/    5]\n","Val\tLoss: 0.519147\tAccuracy: 0.915401\t###END\n","Accuracy: 0.921062\t\n","Loss: 2.737945 [    3/    5]\n","Val\tLoss: 0.492568\tAccuracy: 0.930586\t###END\n","Accuracy: 0.933115\t\n","Loss: 2.711376 [    4/    5]\n","Val\tLoss: 0.468390\tAccuracy: 0.932755\t###END\n"]}]}]}